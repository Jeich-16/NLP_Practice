{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84a34c97",
   "metadata": {},
   "source": [
    "# 전처리 연습 (Tokenize, Cleansing & Normalization, Stemming & Lemmatization)\n",
    "\n",
    "1. 데이터셋(Corpus)을 찾는다. (만들어진 데이터셋, 크롤링, ...)\n",
    "2. 전처리<br>\n",
    "    2-1. 의미가 있는 단어 단위로 Vocabulary<br>\n",
    "    2-2. corpus -> 토큰화 + 전처리 -> 문장"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
